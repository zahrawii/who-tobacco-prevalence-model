#########################################################################################
#
#                    WHO TOBACCO PIPELINE - MCMC DIAGNOSTICS MODULE
#
#   Comprehensive convergence diagnostics for Bayesian hierarchical models.
#   Generates both human-readable log files AND structured tables for analysis.
#
#   OUTPUT STRUCTURE:
#     diagnostics/
#     ├── logs/           Human-readable diagnostic reports
#     ├── tables/         Machine-readable CSV tables for analysis
#     └── README.txt      Documentation
#
#   USAGE:
#     source("R/mcmc_diagnostics.R")
#     diagnostics <- generate_mcmc_diagnostics(
#       samples = mcmc_samples,
#       model_type = "global",      # "global" or "country"
#       model_name = "global",      # "global", "DEU", "USA", etc.
#       gender = "males",
#       data_summary = gender_data  # Optional: for data support analysis
#     )
#
#   TABLES PRODUCED:
#     - rhat_master.csv: All R-hat values with metadata for filtering
#     - convergence_summary.csv: Per-model convergence summary
#     - ess_master.csv: Effective sample sizes
#     - worst_parameters.csv: Top problematic parameters across all models
#
#########################################################################################

cat("  Loading MCMC Diagnostics Module...\n")

# ============================================================================
# DEPENDENCIES
# ============================================================================

suppressPackageStartupMessages({
  library(coda)
  library(dplyr)
  library(tidyr)
})

# ============================================================================
# CONFIGURATION
# ============================================================================

DIAGNOSTICS_DIR <- "diagnostics"
LOGS_DIR <- file.path(DIAGNOSTICS_DIR, "logs")
TABLES_DIR <- file.path(DIAGNOSTICS_DIR, "tables")

# R-hat thresholds
RHAT_GOOD <- 1.05
RHAT_ACCEPTABLE <- 1.10
RHAT_CONCERNING <- 1.50
RHAT_POOR <- 2.00
RHAT_FAILED <- 5.00

# ESS thresholds
ESS_MINIMUM <- 100
ESS_GOOD <- 400

# ============================================================================
# DIRECTORY SETUP
# ============================================================================

setup_diagnostics_directories <- function() {
  dir.create(DIAGNOSTICS_DIR, showWarnings = FALSE, recursive = TRUE)
  dir.create(LOGS_DIR, showWarnings = FALSE, recursive = TRUE)
  dir.create(TABLES_DIR, showWarnings = FALSE, recursive = TRUE)

  # Create README
  readme_path <- file.path(DIAGNOSTICS_DIR, "README.txt")
  if (!file.exists(readme_path)) {
    readme_content <- paste0(
      "MCMC DIAGNOSTICS OUTPUT\n",
      "=======================\n\n",
      "Generated by: WHO Tobacco Pipeline\n",
      "Date: ", format(Sys.time(), "%Y-%m-%d"), "\n\n",
      "DIRECTORY STRUCTURE:\n",
      "  logs/    - Human-readable diagnostic reports (one per model)\n",
      "  tables/  - Machine-readable CSV tables for analysis\n\n",
      "KEY FILES:\n",
      "  tables/rhat_master.csv         - All R-hat values with full metadata\n",
      "  tables/convergence_summary.csv - Per-model summary statistics\n",
      "  tables/ess_master.csv          - Effective sample sizes\n",
      "  tables/worst_parameters.csv    - Problematic parameters across all models\n\n",
      "R-HAT THRESHOLDS:\n",
      "  < 1.05  = Excellent convergence\n",
      "  < 1.10  = Acceptable convergence\n",
      "  < 1.50  = Concerning - may need more iterations\n",
      "  < 2.00  = Poor convergence\n",
      "  >= 2.00 = Failed convergence - results unreliable\n\n",
      "ESS THRESHOLDS:\n",
      "  >= 400  = Good effective sample size\n",
      "  >= 100  = Minimum acceptable\n",
      "  < 100   = Insufficient - need more iterations\n"
    )
    writeLines(readme_content, readme_path)
  }
}

# ============================================================================
# PARAMETER GROUP CLASSIFICATION
# ============================================================================

classify_parameter_group <- function(parameter) {
  case_when(
    # Global intercepts
    grepl("^cig_global_intercept", parameter) ~ "01_cig_global_intercept",
    grepl("^smkextra_global_intercept", parameter) ~ "02_smkextra_global_intercept",
    grepl("^anyextra_global_intercept", parameter) ~ "03_anyextra_global_intercept",

    # Definition code shared effects
    grepl("^cig_def_code", parameter) ~ "04_def_code_shared",

    # Region intercepts
    grepl("^cig_region_intercept\\[", parameter) ~ "05_cig_region_intercept",
    grepl("^smkextra_region_intercept\\[", parameter) ~ "06_smkextra_region_intercept",
    grepl("^anyextra_region_intercept\\[", parameter) ~ "07_anyextra_region_intercept",

    # Country intercepts
    grepl("^cig_country_intercept\\[", parameter) ~ "08_cig_country_intercept",
    grepl("^smkextra_country_intercept\\[", parameter) ~ "09_smkextra_country_intercept",
    grepl("^anyextra_country_intercept\\[", parameter) ~ "10_anyextra_country_intercept",

    # Country-level splines (CIG only)
    grepl("^cig_age_spline\\[", parameter) ~ "11_cig_country_age_spline",
    grepl("^cig_cohort_spline\\[", parameter) ~ "12_cig_country_cohort_spline",

    # Regional spline means
    grepl("^cig_age_spline_region_mean\\[", parameter) ~ "13_cig_regional_age_spline",
    grepl("^cig_cohort_spline_region_mean\\[", parameter) ~ "14_cig_regional_cohort_spline",
    grepl("^smkextra_age_spline_region_mean\\[", parameter) ~ "15_smkextra_regional_age_spline",
    grepl("^smkextra_cohort_spline_region_mean\\[", parameter) ~ "16_smkextra_regional_cohort_spline",
    grepl("^anyextra_age_spline_region_mean\\[", parameter) ~ "17_anyextra_regional_age_spline",
    grepl("^anyextra_cohort_spline_region_mean\\[", parameter) ~ "18_anyextra_regional_cohort_spline",

    # Age-cohort interactions
    grepl("^cig_age_cohort_interaction\\[", parameter) ~ "19_cig_age_cohort_interaction",

    # Linear effects
    grepl("_age_linear_smooth_effect", parameter) ~ "20_linear_age_effects",

    # Global spline means
    grepl("^cig_age_spline_global_mean\\[", parameter) ~ "21_cig_global_age_spline_mean",
    grepl("^cig_cohort_spline_global_mean\\[", parameter) ~ "22_cig_global_cohort_spline_mean",
    grepl("^smkextra_age_spline_global_mean\\[", parameter) ~ "23_smkextra_global_age_spline_mean",
    grepl("^smkextra_cohort_spline_global_mean\\[", parameter) ~ "24_smkextra_global_cohort_spline_mean",
    grepl("^anyextra_age_spline_global_mean\\[", parameter) ~ "25_anyextra_global_age_spline_mean",
    grepl("^anyextra_cohort_spline_global_mean\\[", parameter) ~ "26_anyextra_global_cohort_spline_mean",

    # Survey effects
    grepl("^survey_intercept\\[", parameter) ~ "27_survey_effects",

    # Variance/precision parameters
    grepl("precision", parameter) ~ "28_precision_params",
    grepl("_sd$", parameter) ~ "29_sd_params",
    grepl("_within_region_sd", parameter) ~ "30_within_region_sd",
    grepl("_between_region_sd", parameter) ~ "31_between_region_sd",

    # Intercept SDs
    grepl("intercept.*_sd", parameter) ~ "32_intercept_sd",

    TRUE ~ "99_other"
  )
}

classify_head_type <- function(parameter) {
  case_when(
    grepl("^cig_", parameter) ~ "CIG",
    grepl("^smkextra_", parameter) ~ "SMKEXTRA",
    grepl("^anyextra_", parameter) ~ "ANYEXTRA",
    grepl("^survey_", parameter) ~ "SURVEY",
    grepl("_sd$|precision", parameter) ~ "VARIANCE",
    TRUE ~ "OTHER"
  )
}

get_convergence_status <- function(rhat) {
  case_when(
    is.na(rhat) ~ "NA",
    rhat < RHAT_GOOD ~ "excellent",
    rhat < RHAT_ACCEPTABLE ~ "good",
    rhat < RHAT_CONCERNING ~ "acceptable",
    rhat < RHAT_POOR ~ "concerning",
    rhat < RHAT_FAILED ~ "poor",
    TRUE ~ "failed"
  )
}

# ============================================================================
# CORE DIAGNOSTICS FUNCTION
# ============================================================================

#' Generate Comprehensive MCMC Diagnostics
#'
#' @param samples MCMC samples from nimble (list with $samples element)
#' @param model_type Character: "global" or "country"
#' @param model_name Character: "global", "DEU", "USA", etc.
#' @param gender Character: "males" or "females"
#' @param data_summary Optional data frame for data support analysis
#' @param nimble_constants Optional constants for region/country mapping
#' @param save_log Logical: save human-readable log file
#' @param save_tables Logical: append to master tables
#' @param verbose Logical: print to console
#'
#' @return List with diagnostics data frames
generate_mcmc_diagnostics <- function(samples,
                                       model_type = "global",
                                       model_name = "global",
                                       gender = "males",
                                       data_summary = NULL,
                                       nimble_constants = NULL,
                                       save_log = TRUE,
                                       save_tables = TRUE,
                                       verbose = TRUE) {

  # Setup directories
  setup_diagnostics_directories()

  # Timestamp for this run
  timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
  timestamp_readable <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")

  # Create unique model identifier
  model_id <- paste(model_type, model_name, gender, sep = "_")

  # Log file path
  log_filename <- paste0(model_type, "_", model_name, "_", gender, "_", timestamp, ".txt")
  log_filepath <- file.path(LOGS_DIR, log_filename)

  # Extract samples matrix
  if (is.list(samples) && "samples" %in% names(samples)) {
    mcmc_list <- samples$samples
  } else if (inherits(samples, "mcmc.list")) {
    mcmc_list <- samples
  } else {
    stop("samples must be mcmc.list or list with $samples element")
  }

  combined_samples_matrix <- do.call(rbind, lapply(mcmc_list, as.matrix))
  n_chains <- length(mcmc_list)
  n_iter_per_chain <- nrow(as.matrix(mcmc_list[[1]]))
  n_params <- ncol(combined_samples_matrix)

  # =========================================================================
  # COMPUTE ALL DIAGNOSTICS
  # =========================================================================

  if (verbose) cat(sprintf("  Computing diagnostics for %s...\n", model_id))

  # 1. Gelman-Rubin R-hat
  gelman_result <- tryCatch({
    gelman.diag(mcmc_list, multivariate = FALSE)
  }, error = function(e) {
    warning(sprintf("Gelman diagnostic failed: %s", e$message))
    NULL
  })

  if (!is.null(gelman_result)) {
    rhat_df <- data.frame(
      parameter = rownames(gelman_result$psrf),
      rhat = gelman_result$psrf[, "Point est."],
      rhat_upper_ci = gelman_result$psrf[, "Upper C.I."],
      stringsAsFactors = FALSE
    )
  } else {
    rhat_df <- data.frame(
      parameter = colnames(combined_samples_matrix),
      rhat = NA_real_,
      rhat_upper_ci = NA_real_,
      stringsAsFactors = FALSE
    )
  }

  # 2. Effective Sample Size
  ess_result <- tryCatch({
    effectiveSize(mcmc_list)
  }, error = function(e) {
    warning(sprintf("ESS calculation failed: %s", e$message))
    rep(NA, n_params)
  })

  ess_df <- data.frame(
    parameter = names(ess_result),
    ess = as.numeric(ess_result),
    stringsAsFactors = FALSE
  )

  # 3. Posterior summaries
  posterior_summary <- data.frame(
    parameter = colnames(combined_samples_matrix),
    mean = colMeans(combined_samples_matrix),
    sd = apply(combined_samples_matrix, 2, sd),
    q025 = apply(combined_samples_matrix, 2, quantile, 0.025),
    q500 = apply(combined_samples_matrix, 2, quantile, 0.500),
    q975 = apply(combined_samples_matrix, 2, quantile, 0.975),
    stringsAsFactors = FALSE
  )

  # 4. Combine into master data frame
  master_df <- rhat_df %>%
    left_join(ess_df, by = "parameter") %>%
    left_join(posterior_summary, by = "parameter") %>%
    mutate(
      model_type = model_type,
      model_name = model_name,
      gender = gender,
      model_id = model_id,
      parameter_group = classify_parameter_group(parameter),
      head_type = classify_head_type(parameter),
      status = get_convergence_status(rhat),
      ess_status = case_when(
        is.na(ess) ~ "NA",
        ess >= ESS_GOOD ~ "good",
        ess >= ESS_MINIMUM ~ "acceptable",
        TRUE ~ "insufficient"
      ),
      ci_width = q975 - q025,
      timestamp = timestamp_readable
    ) %>%
    arrange(desc(rhat))

  # 5. Compute chain-by-chain statistics for worst parameters
  worst_params <- head(master_df$parameter[order(-master_df$rhat)], 30)

  chain_stats <- lapply(worst_params, function(param) {
    if (param %in% colnames(combined_samples_matrix)) {
      chain_means <- sapply(mcmc_list, function(ch) mean(as.matrix(ch)[, param]))
      chain_sds <- sapply(mcmc_list, function(ch) sd(as.matrix(ch)[, param]))
      data.frame(
        parameter = param,
        chain_mean_1 = chain_means[1],
        chain_mean_2 = if(length(chain_means) > 1) chain_means[2] else NA,
        chain_mean_3 = if(length(chain_means) > 2) chain_means[3] else NA,
        chain_mean_4 = if(length(chain_means) > 3) chain_means[4] else NA,
        chain_mean_range = max(chain_means) - min(chain_means),
        overall_sd = sd(combined_samples_matrix[, param]),
        stringsAsFactors = FALSE
      )
    } else {
      NULL
    }
  })
  chain_stats_df <- do.call(rbind, Filter(Negate(is.null), chain_stats))

  # 6. Group-level summary
  group_summary <- master_df %>%
    group_by(parameter_group) %>%
    summarise(
      n_params = n(),
      min_rhat = min(rhat, na.rm = TRUE),
      median_rhat = median(rhat, na.rm = TRUE),
      max_rhat = max(rhat, na.rm = TRUE),
      mean_ess = mean(ess, na.rm = TRUE),
      min_ess = min(ess, na.rm = TRUE),
      pct_rhat_above_1.1 = round(mean(rhat > 1.1, na.rm = TRUE) * 100, 1),
      pct_rhat_above_2.0 = round(mean(rhat > 2.0, na.rm = TRUE) * 100, 1),
      pct_ess_below_100 = round(mean(ess < 100, na.rm = TRUE) * 100, 1),
      .groups = "drop"
    ) %>%
    arrange(parameter_group)

  # 7. Head-type summary
  head_summary <- master_df %>%
    group_by(head_type) %>%
    summarise(
      n_params = n(),
      median_rhat = median(rhat, na.rm = TRUE),
      max_rhat = max(rhat, na.rm = TRUE),
      mean_ess = mean(ess, na.rm = TRUE),
      pct_above_1.1 = round(mean(rhat > 1.1, na.rm = TRUE) * 100, 1),
      .groups = "drop"
    )

  # 8. Overall convergence summary
  convergence_summary <- data.frame(
    model_type = model_type,
    model_name = model_name,
    gender = gender,
    model_id = model_id,
    n_chains = n_chains,
    n_iter_per_chain = n_iter_per_chain,
    n_params = n_params,
    n_rhat_above_1.05 = sum(master_df$rhat > 1.05, na.rm = TRUE),
    n_rhat_above_1.1 = sum(master_df$rhat > 1.1, na.rm = TRUE),
    n_rhat_above_1.5 = sum(master_df$rhat > 1.5, na.rm = TRUE),
    n_rhat_above_2.0 = sum(master_df$rhat > 2.0, na.rm = TRUE),
    n_rhat_above_5.0 = sum(master_df$rhat > 5.0, na.rm = TRUE),
    pct_rhat_above_1.1 = round(mean(master_df$rhat > 1.1, na.rm = TRUE) * 100, 2),
    max_rhat = max(master_df$rhat, na.rm = TRUE),
    median_rhat = median(master_df$rhat, na.rm = TRUE),
    worst_param = master_df$parameter[which.max(master_df$rhat)],
    mean_ess = round(mean(master_df$ess, na.rm = TRUE), 0),
    min_ess = min(master_df$ess, na.rm = TRUE),
    n_ess_below_100 = sum(master_df$ess < 100, na.rm = TRUE),
    convergence_grade = case_when(
      max(master_df$rhat, na.rm = TRUE) < 1.05 ~ "A (Excellent)",
      max(master_df$rhat, na.rm = TRUE) < 1.1 ~ "B (Good)",
      max(master_df$rhat, na.rm = TRUE) < 1.5 ~ "C (Acceptable)",
      max(master_df$rhat, na.rm = TRUE) < 2.0 ~ "D (Poor)",
      TRUE ~ "F (Failed)"
    ),
    timestamp = timestamp_readable,
    stringsAsFactors = FALSE
  )

  # =========================================================================
  # SAVE LOG FILE
  # =========================================================================

  if (save_log) {
    sink(log_filepath, split = verbose)

    cat("================================================================================\n")
    cat("              MCMC CONVERGENCE DIAGNOSTICS\n")
    cat("================================================================================\n")
    cat(sprintf("Model Type:     %s\n", model_type))
    cat(sprintf("Model Name:     %s\n", model_name))
    cat(sprintf("Gender:         %s\n", gender))
    cat(sprintf("Model ID:       %s\n", model_id))
    cat(sprintf("Timestamp:      %s\n", timestamp_readable))
    cat(sprintf("Log File:       %s\n", log_filepath))
    cat("--------------------------------------------------------------------------------\n")
    cat(sprintf("Chains:         %d\n", n_chains))
    cat(sprintf("Iterations:     %d per chain (%d total)\n", n_iter_per_chain, n_chains * n_iter_per_chain))
    cat(sprintf("Parameters:     %d\n", n_params))
    cat("================================================================================\n\n")

    # Section 1: Overall Summary
    cat("=== 1. OVERALL CONVERGENCE SUMMARY ===\n\n")
    cat(sprintf("Convergence Grade: %s\n\n", convergence_summary$convergence_grade))
    cat(sprintf("R-hat Statistics:\n"))
    cat(sprintf("  Median R-hat:           %.3f\n", convergence_summary$median_rhat))
    cat(sprintf("  Maximum R-hat:          %.2f (%s)\n",
                convergence_summary$max_rhat, convergence_summary$worst_param))
    cat(sprintf("  Parameters > 1.05:      %d (%.1f%%)\n",
                convergence_summary$n_rhat_above_1.05,
                100 * convergence_summary$n_rhat_above_1.05 / n_params))
    cat(sprintf("  Parameters > 1.10:      %d (%.1f%%)\n",
                convergence_summary$n_rhat_above_1.1,
                100 * convergence_summary$n_rhat_above_1.1 / n_params))
    cat(sprintf("  Parameters > 1.50:      %d (%.1f%%)\n",
                convergence_summary$n_rhat_above_1.5,
                100 * convergence_summary$n_rhat_above_1.5 / n_params))
    cat(sprintf("  Parameters > 2.00:      %d (%.1f%%)\n",
                convergence_summary$n_rhat_above_2.0,
                100 * convergence_summary$n_rhat_above_2.0 / n_params))
    cat(sprintf("  Parameters > 5.00:      %d (%.1f%%)\n\n",
                convergence_summary$n_rhat_above_5.0,
                100 * convergence_summary$n_rhat_above_5.0 / n_params))
    cat(sprintf("ESS Statistics:\n"))
    cat(sprintf("  Mean ESS:               %.0f\n", convergence_summary$mean_ess))
    cat(sprintf("  Minimum ESS:            %.0f\n", convergence_summary$min_ess))
    cat(sprintf("  Parameters ESS < 100:   %d (%.1f%%)\n\n",
                convergence_summary$n_ess_below_100,
                100 * convergence_summary$n_ess_below_100 / n_params))

    # Section 2: By Parameter Group
    cat("=== 2. CONVERGENCE BY PARAMETER GROUP ===\n\n")
    print(as.data.frame(group_summary), row.names = FALSE)
    cat("\n")

    # Section 3: By Head Type
    cat("=== 3. CONVERGENCE BY HEAD TYPE ===\n\n")
    print(as.data.frame(head_summary), row.names = FALSE)
    cat("\n")

    # Section 4: Worst 50 Parameters
    cat("=== 4. WORST 50 PARAMETERS (Highest R-hat) ===\n\n")
    worst_50 <- master_df %>%
      arrange(desc(rhat)) %>%
      head(50) %>%
      select(parameter, parameter_group, rhat, rhat_upper_ci, ess, mean, sd, status)
    print(as.data.frame(worst_50), row.names = FALSE)
    cat("\n")

    # Section 5: Chain-by-Chain Means for Worst Parameters
    cat("=== 5. CHAIN-BY-CHAIN MEANS FOR WORST 15 PARAMETERS ===\n")
    cat("(Large differences between chains indicate non-convergence)\n\n")

    worst_15 <- head(master_df$parameter[order(-master_df$rhat)], 15)
    for (param in worst_15) {
      if (param %in% colnames(combined_samples_matrix)) {
        chain_means <- sapply(mcmc_list, function(ch) mean(as.matrix(ch)[, param]))
        chain_sds <- sapply(mcmc_list, function(ch) sd(as.matrix(ch)[, param]))
        overall_mean <- mean(combined_samples_matrix[, param])
        overall_sd <- sd(combined_samples_matrix[, param])

        cat(sprintf("%s:\n", param))
        cat(sprintf("  R-hat: %.3f | ESS: %.0f\n",
                    master_df$rhat[master_df$parameter == param],
                    master_df$ess[master_df$parameter == param]))
        cat(sprintf("  Overall: mean=%.4f, sd=%.4f\n", overall_mean, overall_sd))
        cat(sprintf("  Chain means: [%s]\n",
                    paste(sprintf("%.4f", chain_means), collapse = ", ")))
        cat(sprintf("  Chain SDs:   [%s]\n",
                    paste(sprintf("%.4f", chain_sds), collapse = ", ")))
        if (overall_sd > 0) {
          cat(sprintf("  Max chain diff: %.4f (%.1f%% of overall SD)\n\n",
                      max(chain_means) - min(chain_means),
                      100 * (max(chain_means) - min(chain_means)) / overall_sd))
        } else {
          cat(sprintf("  Max chain diff: %.4f\n\n", max(chain_means) - min(chain_means)))
        }
      }
    }

    # Section 6: ESS for Worst Parameters
    cat("=== 6. EFFECTIVE SAMPLE SIZE FOR WORST PARAMETERS ===\n\n")
    ess_worst <- master_df %>%
      filter(parameter %in% worst_params) %>%
      arrange(ess) %>%
      head(30) %>%
      select(parameter, ess, rhat, status)
    print(as.data.frame(ess_worst), row.names = FALSE)
    cat("\n")

    # Section 7: Distribution Shape for Worst Parameters
    cat("=== 7. DISTRIBUTION SHAPE FOR WORST 10 PARAMETERS ===\n")
    cat("(Multiple modes suggest label switching or non-identifiability)\n\n")

    worst_10 <- head(master_df$parameter[order(-master_df$rhat)], 10)
    for (param in worst_10) {
      if (param %in% colnames(combined_samples_matrix)) {
        vals <- combined_samples_matrix[, param]
        cat(sprintf("%s:\n", param))
        cat(sprintf("  Range: [%.4f, %.4f]\n", min(vals), max(vals)))
        cat(sprintf("  Quantiles: 5%%=%.4f, 25%%=%.4f, 50%%=%.4f, 75%%=%.4f, 95%%=%.4f\n",
                    quantile(vals, 0.05), quantile(vals, 0.25), quantile(vals, 0.50),
                    quantile(vals, 0.75), quantile(vals, 0.95)))

        # Check for bimodality
        density_est <- density(vals)
        n_peaks <- sum(diff(sign(diff(density_est$y))) == -2)
        cat(sprintf("  Approximate modes: %d\n\n", n_peaks))
      }
    }

    # Section 8: Data Support (if available)
    if (!is.null(data_summary)) {
      cat("=== 8. DATA SUPPORT BY REGION ===\n\n")

      if ("Region_Num" %in% names(data_summary) || "region_consolidated" %in% names(data_summary)) {
        region_col <- if ("Region_Num" %in% names(data_summary)) "Region_Num" else "region_consolidated"

        region_summary <- data_summary %>%
          group_by(!!sym(region_col)) %>%
          summarise(
            n_obs = n(),
            n_countries = n_distinct(wb_country_abv),
            n_cig = if("Type_Cig" %in% names(.)) sum(Type_Cig, na.rm = TRUE) else NA,
            n_smoked = if("Type_Smoked" %in% names(.)) sum(Type_Smoked, na.rm = TRUE) else NA,
            n_any = if("Type_Any" %in% names(.)) sum(Type_Any, na.rm = TRUE) else NA,
            .groups = "drop"
          )

        print(as.data.frame(region_summary), row.names = FALSE)
        cat("\n")
      }
    }

    # Section 9: Key Parameter Correlations
    cat("=== 9. CORRELATIONS BETWEEN KEY PARAMETERS ===\n\n")

    key_params <- c(
      "cig_global_intercept", "smkextra_global_intercept", "anyextra_global_intercept",
      "cig_def_code_shared",
      "cig_age_linear_smooth_effect", "smkextra_age_linear_smooth_effect", "anyextra_age_linear_smooth_effect"
    )

    worst_5 <- head(master_df$parameter[order(-master_df$rhat)], 5)
    params_for_cor <- unique(c(key_params, worst_5))
    params_for_cor <- params_for_cor[params_for_cor %in% colnames(combined_samples_matrix)]

    if (length(params_for_cor) > 1) {
      cor_matrix <- cor(combined_samples_matrix[, params_for_cor])
      cat("Correlation matrix (key + worst 5 parameters):\n")
      print(round(cor_matrix, 3))
      cat("\n(High |correlation| > 0.8 suggests parameters trading off)\n\n")
    }

    # Section 10: Signal Strength Estimates
    cat("=== 10. ESTIMATED SIGNAL STRENGTH ===\n\n")

    for (head in c("smkextra", "anyextra")) {
      intercept_param <- paste0(head, "_global_intercept")
      if (intercept_param %in% colnames(combined_samples_matrix)) {
        vals <- combined_samples_matrix[, intercept_param]
        intercept_mean <- mean(vals)
        intercept_sd <- sd(vals)
        p_implied <- plogis(intercept_mean)

        cat(sprintf("%s:\n", toupper(head)))
        cat(sprintf("  Global intercept: %.3f (SD: %.3f)\n", intercept_mean, intercept_sd))
        cat(sprintf("  Implied probability: %.1f%% [%.1f%%, %.1f%%]\n\n",
                    100 * p_implied,
                    100 * plogis(intercept_mean - 2*intercept_sd),
                    100 * plogis(intercept_mean + 2*intercept_sd)))
      }
    }

    cat("================================================================================\n")
    cat("                         END OF DIAGNOSTICS\n")
    cat("================================================================================\n")

    sink()

    if (verbose) cat(sprintf("  Log saved to: %s\n", log_filepath))
  }

  # =========================================================================
  # SAVE TO MASTER TABLES
  # =========================================================================

  if (save_tables) {
    # Master R-hat table
    rhat_master_path <- file.path(TABLES_DIR, "rhat_master.csv")
    master_export <- master_df %>%
      select(model_type, model_name, gender, model_id, parameter, parameter_group,
             head_type, rhat, rhat_upper_ci, ess, mean, sd, q025, q500, q975,
             ci_width, status, ess_status, timestamp)

    if (file.exists(rhat_master_path)) {
      write.table(master_export, rhat_master_path,
                  sep = ",", row.names = FALSE, col.names = FALSE, append = TRUE)
    } else {
      write.csv(master_export, rhat_master_path, row.names = FALSE)
    }

    # Convergence summary table
    conv_summary_path <- file.path(TABLES_DIR, "convergence_summary.csv")
    if (file.exists(conv_summary_path)) {
      write.table(convergence_summary, conv_summary_path,
                  sep = ",", row.names = FALSE, col.names = FALSE, append = TRUE)
    } else {
      write.csv(convergence_summary, conv_summary_path, row.names = FALSE)
    }

    # ESS master table
    ess_master_path <- file.path(TABLES_DIR, "ess_master.csv")
    ess_export <- master_df %>%
      select(model_type, model_name, gender, model_id, parameter, parameter_group,
             ess, ess_status, rhat, timestamp)

    if (file.exists(ess_master_path)) {
      write.table(ess_export, ess_master_path,
                  sep = ",", row.names = FALSE, col.names = FALSE, append = TRUE)
    } else {
      write.csv(ess_export, ess_master_path, row.names = FALSE)
    }

    if (verbose) cat(sprintf("  Tables appended to: %s\n", TABLES_DIR))
  }

  # =========================================================================
  # RETURN RESULTS
  # =========================================================================

  return(list(
    master_df = master_df,
    group_summary = group_summary,
    head_summary = head_summary,
    convergence_summary = convergence_summary,
    chain_stats = chain_stats_df,
    log_filepath = log_filepath
  ))
}

# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

#' Generate Worst Parameters Report Across All Models
#'
#' Reads the master R-hat table and generates a report of worst parameters
generate_worst_parameters_report <- function(top_n = 100) {
  rhat_master_path <- file.path(TABLES_DIR, "rhat_master.csv")

  if (!file.exists(rhat_master_path)) {
    cat("  No master R-hat table found. Run diagnostics first.\n")
    return(NULL)
  }

  master <- read.csv(rhat_master_path, stringsAsFactors = FALSE)

  # Get worst parameters across all models
  worst <- master %>%
    arrange(desc(rhat)) %>%
    head(top_n) %>%
    select(model_id, parameter, parameter_group, head_type, rhat, ess, status)

  # Save report
  worst_path <- file.path(TABLES_DIR, "worst_parameters.csv")
  write.csv(worst, worst_path, row.names = FALSE)

  cat(sprintf("  Worst %d parameters saved to: %s\n", top_n, worst_path))

  return(worst)
}

#' Generate Summary Report Across All Models
generate_all_models_summary <- function() {
  conv_summary_path <- file.path(TABLES_DIR, "convergence_summary.csv")

  if (!file.exists(conv_summary_path)) {
    cat("  No convergence summary found. Run diagnostics first.\n")
    return(NULL)
  }

  summary <- read.csv(conv_summary_path, stringsAsFactors = FALSE)

  cat("\n=== ALL MODELS CONVERGENCE SUMMARY ===\n\n")

  summary_display <- summary %>%
    select(model_id, convergence_grade, max_rhat, median_rhat,
           n_rhat_above_1.1, pct_rhat_above_1.1, mean_ess, min_ess, worst_param)

  print(as.data.frame(summary_display), row.names = FALSE)

  # Overall assessment
  cat("\n=== OVERALL ASSESSMENT ===\n")
  cat(sprintf("  Total models:            %d\n", nrow(summary)))
  cat(sprintf("  Models with grade A/B:   %d\n",
              sum(grepl("^[AB]", summary$convergence_grade))))
  cat(sprintf("  Models with grade F:     %d\n",
              sum(grepl("^F", summary$convergence_grade))))
  cat(sprintf("  Worst model:             %s (R-hat: %.2f)\n",
              summary$model_id[which.max(summary$max_rhat)],
              max(summary$max_rhat)))

  return(summary)
}

#' Clear All Diagnostic Tables (for fresh run)
clear_diagnostic_tables <- function() {
  tables <- c("rhat_master.csv", "convergence_summary.csv",
              "ess_master.csv", "worst_parameters.csv")

  for (tbl in tables) {
    path <- file.path(TABLES_DIR, tbl)
    if (file.exists(path)) {
      file.remove(path)
      cat(sprintf("  Removed: %s\n", path))
    }
  }
  cat("  Diagnostic tables cleared.\n")
}

# ============================================================================
# GT TABLE GENERATION FOR ELEGANT DISPLAY
# ============================================================================

#' Generate Elegant GT Table for Convergence Summary
#'
#' Creates a publication-quality table of convergence diagnostics
generate_convergence_gt_table <- function(output_file = NULL) {

  if (!requireNamespace("gt", quietly = TRUE)) {
    cat("  Package 'gt' required for elegant tables. Install with: install.packages('gt')\n")
    return(NULL)
  }

  conv_summary_path <- file.path(TABLES_DIR, "convergence_summary.csv")

  if (!file.exists(conv_summary_path)) {
    cat("  No convergence summary found. Run diagnostics first.\n")
    return(NULL)
  }

  library(gt)

  summary <- read.csv(conv_summary_path, stringsAsFactors = FALSE)

  # Prepare data for display
  table_data <- summary %>%
    mutate(
      Gender = case_when(
        gender == "males" ~ "Men",
        gender == "females" ~ "Women",
        TRUE ~ gender
      ),
      Model = tools::toTitleCase(model_name),
      Grade = convergence_grade,
      `Max R-hat` = sprintf("%.2f", max_rhat),
      `Median R-hat` = sprintf("%.3f", median_rhat),
      `% > 1.1` = sprintf("%.1f%%", pct_rhat_above_1.1),
      `Mean ESS` = sprintf("%.0f", mean_ess),
      `Worst Parameter` = worst_param
    ) %>%
    select(model_type, Model, Gender, Grade, `Max R-hat`, `Median R-hat`,
           `% > 1.1`, `Mean ESS`, `Worst Parameter`)

  # Create GT table
  gt_table <- table_data %>%
    gt() %>%
    tab_header(
      title = md("**MCMC Convergence Diagnostics Summary**"),
      subtitle = md("Model-level convergence assessment")
    ) %>%
    cols_label(
      model_type = "Type",
      Model = "Model",
      Gender = "Gender",
      Grade = "Grade",
      `Max R-hat` = "Max R-hat",
      `Median R-hat` = "Median R-hat",
      `% > 1.1` = "% Above 1.1",
      `Mean ESS` = "Mean ESS",
      `Worst Parameter` = "Worst Parameter"
    ) %>%
    tab_style(
      style = list(
        cell_fill(color = "#1B5E20"),
        cell_text(color = "white", weight = "bold")
      ),
      locations = cells_body(
        columns = Grade,
        rows = grepl("^A", Grade)
      )
    ) %>%
    tab_style(
      style = list(
        cell_fill(color = "#4CAF50"),
        cell_text(color = "white")
      ),
      locations = cells_body(
        columns = Grade,
        rows = grepl("^B", Grade)
      )
    ) %>%
    tab_style(
      style = cell_fill(color = "#FFF59D"),
      locations = cells_body(
        columns = Grade,
        rows = grepl("^C", Grade)
      )
    ) %>%
    tab_style(
      style = cell_fill(color = "#FFCDD2"),
      locations = cells_body(
        columns = Grade,
        rows = grepl("^D", Grade)
      )
    ) %>%
    tab_style(
      style = list(
        cell_fill(color = "#E57373"),
        cell_text(weight = "bold")
      ),
      locations = cells_body(
        columns = Grade,
        rows = grepl("^F", Grade)
      )
    ) %>%
    tab_style(
      style = list(
        cell_fill(color = "#F5F5F5"),
        cell_text(weight = "bold")
      ),
      locations = cells_column_labels()
    ) %>%
    tab_footnote(
      footnote = md("**Grades**: A (Excellent, max R-hat < 1.05), B (Good, < 1.10), C (Acceptable, < 1.50), D (Poor, < 2.00), F (Failed, >= 2.00)"),
      locations = cells_column_labels(columns = Grade)
    ) %>%
    tab_source_note(
      source_note = md("*ESS = Effective Sample Size. R-hat < 1.1 indicates acceptable convergence.*")
    ) %>%
    tab_options(
      table.width = pct(100),
      table.font.size = px(10),
      heading.title.font.size = px(14),
      heading.title.font.weight = "bold",
      column_labels.font.weight = "bold",
      data_row.padding = px(6)
    )

  # Save if output file specified
  if (!is.null(output_file)) {
    gtsave(gt_table, output_file)
    cat(sprintf("  GT table saved to: %s\n", output_file))
  }

  return(gt_table)
}

# ============================================================================
# MODULE LOADED
# ============================================================================

cat("  MCMC Diagnostics Module loaded.\n")
cat("  Functions available:\n")
cat("    - generate_mcmc_diagnostics()       Generate diagnostics for one model\n")
cat("    - generate_worst_parameters_report() Find worst parameters across all models\n")
cat("    - generate_all_models_summary()      Summary across all models\n")
cat("    - generate_convergence_gt_table()    Create elegant GT table\n")
cat("    - clear_diagnostic_tables()          Clear tables for fresh run\n")
